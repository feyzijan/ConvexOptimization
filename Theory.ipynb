{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Proof that the probability simplex is convex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a set $C$ is convex if for any $x_1,x_2\\in C$ and any $\\theta$ such that $0\\le \\theta \\le 1$ we have\n",
    "\n",
    "$$\n",
    "\\theta x_1 + (1-\\theta) x_2 \\in C\n",
    "$$\n",
    "\n",
    "Using the definition above prove that the probability simplex, i.e. the set of vectors that satisfy $x \\succeq 0$, $\\mathbf{1}^\\top x = 1$, is convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let C the probability simplex of dimension $n \\in \\mathbb{N}$\n",
    " \n",
    " \n",
    "Let $(x_1,x_2) \\in C^2$ and $\\theta \\in \\mathbb{R}$ with $ 0\\leq \\theta \\leq 1$\n",
    " \n",
    " \n",
    "Let's show that $x = \\theta * x_1 + (1-\\theta) * x_2 \\in C$\n",
    " \n",
    "First of all, for the element wise property :\n",
    " \n",
    "$ \\forall i \\in [[1,n]],\\ x_i = \\theta * (x_1)_i + (1-\\theta) * (x_2)_i >= 0$ as sum of positive reals. Which proves that $x \\succeq 0$.\n",
    " \n",
    "For the second property:\n",
    " \n",
    "$\\mathbf{1}^\\top x = \\theta * \\mathbf{1}^\\top x_1 + (1-\\theta) * \\mathbf{1}^\\top x_2 = \\theta + (1 - \\theta) = 1$.\n",
    " \n",
    "Both properties are proved hence x is in C and C is convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Duality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the optimisation problem\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\displaystyle \\min_{x,y} & e^{-x}\\\\\n",
    "s.t. & \\frac{x^2}{y}\\le 0\\end{array}\\tag{1}\n",
    "$$\n",
    "\n",
    "with variables $x$ and $y$ and domain $\\mathcal{D} = \\{(x,y): y >0\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1.   Justify why this is a convex optimisation problem.\n",
    "2.   Find the feasibility set and the optimal value of the problem.\n",
    "3.   Give the Lagrangian.\n",
    "4.   The dual function is (*the derivation from the Lagrangian is skipped because it is challenging*)\n",
    "$$\n",
    "\\displaystyle g(\\lambda) = \\left\\{\\begin{array}{ll}0 & \\lambda \\ge 0,\\\\ -\\infty & \\lambda < 0\\end{array}\\right.\n",
    "$$\n",
    "Write the dual problem.\n",
    "5.   Compute the dual optimal value and the duality gap.\n",
    "6.   Explain why the duality gap is not zero.\n",
    "7.   (*Hard*) In part 4 the dual function is given because its derivation is difficult. Using the Lagrangian obtained in part 3, attempt to prove that the dual function is the one given in part 4. (*Tip: split the analysis in two cases: $\\lambda \\ge 0$ and $\\lambda < 0$*).\n",
    "8.   (*Hard*) Consider the optimal value $p^*(u)$ of the perturbed problem \n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\displaystyle  \\min_{x,y} & e^{-x}\\\\\n",
    "s.t. & \\frac{x^2}{y}\\le u\\end{array}\n",
    "$$\n",
    "Verify that for $u=1$ and $\\lambda^*=0$ the global sensitivity inequality\n",
    "$$\n",
    "p^*(u) \\ge p^*(0) - \\lambda^* u\n",
    "$$\n",
    "does not hold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the dual function of the LP\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\min & c^\\top x\\\\\n",
    "s.t. & G x \\preceq h\\\\\n",
    "& Ax =b.\n",
    "\\end{array}\n",
    "$$\n",
    "Give the dual problem, and make the implicit equality constraints explicit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lagrangian is \n",
    "\n",
    "$$\n",
    "L(x,\\lambda,\\nu) = c^\\top x + \\lambda^\\top (Gx-h) + \\nu^\\top (Ax-b) = (c^\\top + \\lambda^\\top G + \\nu^\\top A)x - \\lambda^\\top h - \\nu^\\top b,\n",
    "$$\n",
    "\n",
    "which is an affine function of $x$. It follows that the dual function is given by\n",
    "\n",
    "$$\n",
    "g(\\lambda,\\nu)= \\inf_x L(x,\\lambda,\\nu) = \\left\\{\\begin{array}{ll}-\\lambda^\\top h - \\nu^\\top b & c+G^\\top \\lambda + A^\\top \\nu =0\\\\\n",
    "-\\infty & \\text{otherwise}\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "The dual problem is\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\max & g(\\lambda,\\nu)\\\\\n",
    "s.t. & \\lambda \\succeq 0.\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "After making the implicit constraints explicit, we obtain\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\max & -\\lambda^\\top h - \\nu^\\top b\\\\\n",
    "s.t. & c+G^\\top \\lambda + A^\\top \\nu =0\\\\\n",
    "& \\lambda \\succeq 0.\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulate the following problems as LPs. Explain in detail the relation between the optimal solution of each problem and the solution of its equivalent LP.\n",
    "1.   Minimize $||Ax - b||_\\infty$ ($\\ell_\\infty$-norm approximation).\n",
    "2.   Minimize $||Ax - b||_1$ ($\\ell_1$-norm approximation).\n",
    "3.   Minimize $||Ax - b||_1$ subject to $||x||_\\infty \\le 1$.\n",
    "4.   Minimize $||x||_1$ subject to $||Ax - b||_\\infty \\le 1$.\n",
    "5.   Minimize $||Ax - b||_1 + ||x||_\\infty$.\n",
    "\n",
    "In each problem, $A \\in \\mathbb{R}^{m\\times n}$ and $b\\in  \\mathbb{R}^{m}$ are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.    The equivalent LP is\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\displaystyle \\min_{t,x} &t\\\\ \n",
    "\\text{s.t. } &-t \\mathbf{1} \\preccurlyeq Ax-b \\preccurlyeq t\\mathbf{1}\n",
    "\\end{array}\\tag{1}\n",
    "$$\n",
    "\n",
    "To see the equivalence, assume $x$ is fixed in this problem and we optimise only over $t$. The constraints say that $-t \\le a_k^\\top x -b_k \\le t$ for all $k$, which implies $t \\ge \\max_k |a_k^\\top x -b_k| = ||Ax - b||_\\infty$.\n",
    "\n",
    "Clearly, if $x$ is fixed, the optimal value over $t$ of the LP is $||Ax - b||_\\infty$. Thus, optimising over $t$ and $x$ simultaneously is equivalent to the original problem.\n",
    "\n",
    "2.    The equivalent LP is\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\displaystyle \\min_{t,x} &\\mathbf{1}^{\\top}t\\\\ \n",
    "\\text{s.t. } &-t  \\preccurlyeq Ax-b \\preccurlyeq t\n",
    "\\end{array}\\tag{2}\n",
    "$$\n",
    "\n",
    "Assume $x$ is fixed and we optimise over $t$. The constraints say that $-t_k \\le a_k^\\top x -b_k \\le t_k$ for all $k$. Note that each constraints depends only on one $t_k$ and that the objective function is the sum of the $t_k$. So the objective function is separable and the optimum over $t_k$ is achieved by $t_k = |a_k^\\top x -b_k |$. \n",
    "\n",
    "Clearly, if $x$ is fixed, the optimal value over $t$ of the LP is $||Ax - b||_1$. Thus, optimising over $t$ and $x$ simultaneously is equivalent to the original problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.   The equivalent LP is\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\displaystyle \\min_{t,x} &\\mathbf{1}^{\\top}t\\\\ \n",
    "\\text{s.t. } &-t  \\preccurlyeq Ax-b \\preccurlyeq t\\\\\n",
    "& -\\mathbf{1} \\preccurlyeq x \\preccurlyeq \\mathbf{1}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "This is obtained from the problem $(2)$ plus the constraint $||x||_\\infty \\le 1$. This is handled like Part $1$: if $|x_k| \\le 1$ for all $k$, then $1\\ge \\max_k |x_k| = ||x||_\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.   The equivalent LP is\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\displaystyle \\min_{t,x} &\\mathbf{1}^{\\top}t\\\\ \n",
    "\\text{s.t. } &-t  \\preccurlyeq x \\preccurlyeq t\\\\\n",
    "& -\\mathbf{1} \\preccurlyeq Ax-b \\preccurlyeq \\mathbf{1}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "This is handled in the same why as the Part $3$, where $x$ and $Ax-b$ have been swapped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.   The equivalent LP is\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\displaystyle \\min_{t,s,x} &\\mathbf{1}^{\\top}t + s\\\\ \n",
    "\\text{s.t. } &-t  \\preccurlyeq Ax-b \\preccurlyeq t\\\\\n",
    "& -s\\mathbf{1} \\preccurlyeq x \\preccurlyeq s\\mathbf{1}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "which is nothing else than the sum of the objective functions of $(1)$ and $(2)$ and the intersection of the constraints of $(1)$ and $(2)$ (where $||Ax-b||_\\infty$ is now $||x||_\\infty$)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
